{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VandadII/colab-notebooks/blob/main/FLUX_1_dev_Gen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FLUX.1 Gen\n"
      ],
      "metadata": {
        "collapsed": false,
        "id": "zl-S0m3pkQC5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ostris/ai-toolkit\n",
        "!mkdir -p /content/lora  # this is where your LoRA .safetensors file goes"
      ],
      "metadata": {
        "id": "BvAG0GKAh59G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08606f85-8ffc-4ea0-c00e-9001fe552094"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'ai-toolkit' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Put your LoRA in the `/content/lora` folder"
      ],
      "metadata": {
        "id": "UFUW4ZMmnp1V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XGZqVER_aQJW",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!cd ai-toolkit && git submodule update --init --recursive && pip install -r requirements.txt # numpy==1.25.0 --force-reinstall\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîç Test for ABI mismatches (like numpy dtype size errors)"
      ],
      "metadata": {
        "id": "Laji6UCuzWND"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    import numpy as np\n",
        "    import diffusers\n",
        "    from diffusers.schedulers import DDIMScheduler  # or DDPM if that's your config\n",
        "\n",
        "    print(\"‚úÖ Environment looks stable. No ABI issues.\")\n",
        "    print(\"Numpy version:\", np.__version__)\n",
        "except Exception as e:\n",
        "    print(\"‚ùå ABI Error Detected:\")\n",
        "    print(e)"
      ],
      "metadata": {
        "id": "b_GBOTAVzLQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model License\n",
        "Training currently only works with FLUX.1-dev. Which means anything you train will inherit the non-commercial license. It is also a gated model, so you need to accept the license on HF before using it. Otherwise, this will fail. Here are the required steps to setup a license.\n",
        "\n",
        "Sign into HF and accept the model access here [black-forest-labs/FLUX.1-dev](https://huggingface.co/black-forest-labs/FLUX.1-dev)\n",
        "\n",
        "[Get a READ key from huggingface](https://huggingface.co/settings/tokens/new?) and place it in the next cell after running it."
      ],
      "metadata": {
        "id": "OV0HnOI6o8V6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "# Prompt for the token\n",
        "hf_token = getpass.getpass('Enter your HF access token and press enter: ')\n",
        "\n",
        "# Set the environment variable\n",
        "os.environ['HF_TOKEN'] = hf_token\n",
        "\n",
        "print(\"HF_TOKEN environment variable has been set.\")"
      ],
      "metadata": {
        "id": "3yZZdhFRoj2m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15a8baf6-f04c-4ad5-8d9a-4e7bc6ad6336"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your HF access token and press enter: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n",
            "HF_TOKEN environment variable has been set.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "sys.path.append('/content/ai-toolkit')\n",
        "from toolkit.job import run_job\n",
        "from collections import OrderedDict\n",
        "from PIL import Image\n",
        "import os\n",
        "os.environ[\"HF_HUB_ENABLE_HF_TRANSFER\"] = \"1\""
      ],
      "metadata": {
        "id": "9gO2EzQ1kQC8"
      },
      "outputs": [],
      "execution_count": 5
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup\n",
        "\n",
        "This is your config. It is documented pretty well. Normally you would do this as a yaml file, but for colab, this will work. This will run as is without modification, but feel free to edit as you want."
      ],
      "metadata": {
        "id": "N8UUFzVRigbC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict\n",
        "\n",
        "job_to_run = OrderedDict([\n",
        "    ('job', 'generate'),\n",
        "    ('config', OrderedDict([\n",
        "        ('name', 'flux_image_gen'),\n",
        "        ('process', [\n",
        "            OrderedDict([\n",
        "                ('type', 'to_folder'),\n",
        "                ('output_folder', '/content/generated'),  # where your images will be saved\n",
        "                ('device', 'cuda:0'),\n",
        "                ('dtype', 'float16'),\n",
        "                ('model', OrderedDict([\n",
        "                    ('name_or_path', 'black-forest-labs/FLUX.1-dev'),\n",
        "                    ('is_flux', True),\n",
        "                    ('quantize', True),\n",
        "                    # Optional: Add LoRA file path here to personalize generation.\n",
        "                    # Leave this line commented if testing the base FLUX.1-dev model only.\n",
        "                    # ('lora', '/content/lora/your_lora.safetensors')  # <-- put your LoRA here\n",
        "                ])),\n",
        "                ('generate', OrderedDict([\n",
        "                    ('sampler', 'flowmatch'),\n",
        "                    ('width', 1024),\n",
        "                    ('height', 1024),\n",
        "                    ('prompts', [\n",
        "                        'a woman with red hair, playing chess at the park, bomb going off in the background',\n",
        "                        'a woman holding a coffee cup, in a beanie, sitting at a cafe',\n",
        "                        'a horse is a DJ at a night club, fish eye lens, smoke machine, laser lights, holding a martini',\n",
        "                        'a man showing off his cool new t shirt at the beach, a shark is jumping out of the water in the background',\n",
        "                        'a bear building a log cabin in the snow covered mountains',\n",
        "                        'woman playing the guitar, on stage, singing a song, laser lights, punk rocker',\n",
        "                        'hipster man with a beard, building a chair, in a wood shop',\n",
        "                        'photo of a man, white background, medium shot, modeling clothing, studio lighting, white backdrop',\n",
        "                        'a man holding a sign that says, \"this is a sign\"',\n",
        "                        'a bulldog, in a post apocalyptic world, with a shotgun, in a leather jacket, in a desert, with a motorcycle'\n",
        "                    ]),\n",
        "                    ('neg', ''),\n",
        "                    ('seed', 42),\n",
        "                    ('guidance_scale', 4),\n",
        "                    ('sample_steps', 20),\n",
        "                    ('num_repeats', 1)\n",
        "                ]))\n",
        "            ])\n",
        "        ])\n",
        "    ]))\n",
        "])\n"
      ],
      "metadata": {
        "id": "_t28QURYjRQO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run it"
      ],
      "metadata": {
        "id": "h6F1FlM2Wb3l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run_job(job_to_run)\n"
      ],
      "metadata": {
        "id": "HkajwI8gteOh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}